{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "chubby-force",
   "metadata": {},
   "source": [
    "# GMM for anomaly detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "light-reverse",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rcParams\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import mixture\n",
    "from sklearn.mixture import GaussianMixture as GMM\n",
    "from sklearn import datasets\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn import metrics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sapphire-lesbian",
   "metadata": {},
   "source": [
    "#  Get DK data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caroline-miami",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "with zipfile.ZipFile('hackathon_kpis_anonymised.zip', 'r') as zip_ref:\n",
    "    zip_ref.extractall('.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "confirmed-think",
   "metadata": {},
   "source": [
    "# Gaussian Mixture Models EM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "respective-criterion",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('hackathon_kpis_anonymised.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "given-river",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "personalized-intake",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sort_values(by = 'timestamp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incredible-wesley",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "expanded-convert",
   "metadata": {},
   "outputs": [],
   "source": [
    "nan_values = df.isna()\n",
    "nan_columns = nan_values.any()\n",
    "\n",
    "columns_with_nan = df.columns[nan_columns].tolist()\n",
    "print(columns_with_nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "formal-spokesman",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.fillna(0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "controlled-springer",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "outside-reduction",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "indonesian-equity",
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_occurrences = pd.DataFrame(df.cell_name.value_counts())\n",
    "cell_occurrences.columns = ['count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "otherwise-louisville",
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_occurrences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stuffed-setup",
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_occurrences['count'].hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "suspended-indianapolis",
   "metadata": {},
   "source": [
    "### Optimal clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "maritime-compilation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# full dataset\n",
    "\n",
    "XX = np.array(df[['avail_period_duration', 'bandwidth',\n",
    "       'num_voice_attempts', 'num_data_attempts', 'voice_tot_failure_rate',\n",
    "       'data_tot_failure_rate', 'unavail_unplan_rate', 'unavail_total_rate',\n",
    "       'voice_setup_failure_rate', 'voice_drop_rate',\n",
    "       'data_setup_failure_rate', 'data_drop_rate', 'throughput_rate',\n",
    "       'ho_failure_rate']].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sorted-implement",
   "metadata": {},
   "outputs": [],
   "source": [
    "XX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "retained-thomas",
   "metadata": {},
   "outputs": [],
   "source": [
    "# selecting n columns of the dataset\n",
    "\n",
    "n = 14\n",
    "X = XX[:,:n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "excited-honolulu",
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting the dataset into train-test by using dates\n",
    "\n",
    "nobs = df[df['timestamp']>='2020-11'].shape[0]\n",
    "\n",
    "X_train  = X[:-nobs,:]\n",
    "X_test = X[-nobs:,:]\n",
    "\n",
    "# getting the train-test percentage\n",
    "\n",
    "print('The total dataset consists of',X.shape[0],'rows')\n",
    "print('The training dataset consists of',X_train.shape[0],'rows')\n",
    "print('The test dataset consists of',X_test.shape[0],'rows')\n",
    "print(np.round(X_train.shape[0]/X.shape[0]*100), '-',np.round(X_test.shape[0]/X.shape[0]*100),'percent split')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "confident-circuit",
   "metadata": {},
   "source": [
    "###  Setting parameter on split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "flexible-walter",
   "metadata": {},
   "source": [
    "- If you want to train on the whole dataset set **train_test = False**\n",
    "- If you want to plit the dataset in training and testing set **train_test = True**\n",
    "<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "indian-artist",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parameter  to set\n",
    "train_test = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "processed-church",
   "metadata": {},
   "outputs": [],
   "source": [
    "# random sample for finding best cluster number\n",
    "\n",
    "\n",
    "if  train_test == True:\n",
    "    size_sample = 10000\n",
    "    randomly_sampled = np.random.choice(X_train.shape[0], size=size_sample, replace=False)\n",
    "\n",
    "    X_sample = X[randomly_sampled,:]\n",
    "else:\n",
    "    size_sample = 10000\n",
    "    randomly_sampled = np.random.choice(X.shape[0], size=size_sample, replace=False)\n",
    "\n",
    "    X_sample = X[randomly_sampled,:]\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coordinate-light",
   "metadata": {},
   "outputs": [],
   "source": [
    "rcParams['figure.figsize'] = 8,3\n",
    "\n",
    "if train_test  ==  True:\n",
    "    n_components = np.arange(1, 12)\n",
    "    models = [GMM(n, covariance_type='full', random_state=0).fit(X_sample)\n",
    "              for n in n_components]\n",
    "\n",
    "    plt.plot(n_components, [m.bic(X_train) for m in models], label='BIC')\n",
    "    plt.plot(n_components, [m.aic(X_train) for m in models], label='AIC')\n",
    "    plt.legend(loc='best')\n",
    "    plt.xlabel('n_components');\n",
    "else:\n",
    "    n_components = np.arange(1, 12)\n",
    "    models = [GMM(n, covariance_type='full', random_state=0).fit(X_sample)\n",
    "              for n in n_components]\n",
    "\n",
    "    plt.plot(n_components, [m.bic(X) for m in models], label='BIC')\n",
    "    plt.plot(n_components, [m.aic(X) for m in models], label='AIC')\n",
    "    plt.legend(loc='best')\n",
    "    plt.xlabel('n_components');\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "communist-final",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_components = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "smoking-thailand",
   "metadata": {},
   "outputs": [],
   "source": [
    "if train_test  ==  True:\n",
    "    gmm=GMM(n_components, n_init=1).fit(X_train) \n",
    "    labels=gmm.predict(X_test)\n",
    "    scores = gmm.predict_proba(X_test)\n",
    "else:\n",
    "    gmm=GMM(n_components, n_init=1).fit(X) \n",
    "    labels=gmm.predict(X)\n",
    "    scores = gmm.predict_proba(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dried-helmet",
   "metadata": {},
   "outputs": [],
   "source": [
    "#eps = 1/n_components +0.1/n_components\n",
    "eps=0.55"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "confident-creation",
   "metadata": {},
   "outputs": [],
   "source": [
    "if train_test:\n",
    "    indices_test = [i for i, x in enumerate(scores.max(axis=1)<eps) if x == True]\n",
    "    df_test = df[df['timestamp']>='2020-11'].reset_index().drop('index',1)\n",
    "    df_test['anomaly'] = np.where(df_test.index.isin(indices_test), 1, 0)\n",
    "    df_test =  df_test.set_index('timestamp')\n",
    "    anomaly_dataset = df_test[df_test['anomaly']==1]\n",
    "    print('The model has found',df_test[df_test['anomaly']==1].shape[0],'anomalies')\n",
    "    print('associated to the following cells:')\n",
    "    print(df_test[df_test['anomaly']==1]['cell_name'].value_counts())\n",
    "\n",
    "else:\n",
    "    indices = [i for i, x in enumerate(scores.max(axis=1)<eps) if x == True]\n",
    "    df_tot = df.reset_index().drop('index',1)\n",
    "    df_tot['anomaly'] = np.where(df.index.isin(indices), 1, 0)\n",
    "    df_tot =  df_tot.set_index('timestamp') \n",
    "    anomaly_dataset = df_tot[df_tot['anomaly']==1]\n",
    "    print('The model has found',df_tot[df_tot['anomaly']==1].shape[0],'anomalies')\n",
    "    print('associated to the following cells:')\n",
    "    print(df_tot[df_tot['anomaly']==1]['cell_name'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "excited-posting",
   "metadata": {},
   "source": [
    "## List of all anomalies identified with GMM using 2 components and eps for thresholding probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "independent-evanescence",
   "metadata": {},
   "outputs": [],
   "source": [
    "anomaly_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "narrative-archive",
   "metadata": {},
   "outputs": [],
   "source": [
    "anomaly_df = pd.DataFrame(anomaly_dataset['cell_name'].value_counts())\n",
    "anomaly_df = anomaly_df.reset_index()\n",
    "anomaly_df.columns = ['cell_name','count']\n",
    "anomaly_df['site'] = anomaly_df['cell_name'].apply(lambda x: x[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sorted-police",
   "metadata": {},
   "outputs": [],
   "source": [
    "site_cnt = anomaly_df['site'].value_counts().to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "portuguese-editor",
   "metadata": {},
   "outputs": [],
   "source": [
    "anomaly_df['site_cnt'] = anomaly_df['site'].apply(lambda x: int(site_cnt[x]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "above-inclusion",
   "metadata": {},
   "outputs": [],
   "source": [
    "anomaly_df = anomaly_df.sort_values('cell_name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alert-certification",
   "metadata": {},
   "outputs": [],
   "source": [
    "anomaly_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "multiple-breakfast",
   "metadata": {},
   "outputs": [],
   "source": [
    "anomaly_df[anomaly_df['site'] =='00']['cell_name'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "underlying-macintosh",
   "metadata": {},
   "source": [
    "## Example of anomalous behaviour in a cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "durable-absence",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_plot = {}\n",
    "\n",
    "if train_test:\n",
    "    for i in  anomaly_dataset['cell_name'].value_counts().index:\n",
    "        df_plot[i] = df_test[df_test['cell_name']== i]\n",
    "else:\n",
    "    for i in  anomaly_dataset['cell_name'].value_counts().index:\n",
    "        df_plot[i] = df_tot[df_tot['cell_name']== i]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chief-attitude",
   "metadata": {},
   "outputs": [],
   "source": [
    "if train_test:\n",
    "    cell_most_anomalous_events  = anomaly_dataset['cell_name'].value_counts().index[0]\n",
    "else:\n",
    "    cell_most_anomalous_events = anomaly_dataset['cell_name'].value_counts().index[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "blessed-inspector",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking how many timestamps we have for the cell with most number of anomlies:\n",
    "print('The cell with most anomalous events has\\n\\n',cell_occurrences.loc[cell_most_anomalous_events], '\\n\\ntimestamps')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "demonstrated-avenue",
   "metadata": {},
   "outputs": [],
   "source": [
    "anomaly_dataset[anomaly_dataset['cell_name'] == cell_most_anomalous_events]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "athletic-battery",
   "metadata": {},
   "source": [
    "## Some plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "racial-editing",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_plot[cell_most_anomalous_events].plot(subplots = True, figsize = (20,20));\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "republican-shaft",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_plot['02_31Q'].plot(subplots = True, figsize = (20,20));"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
